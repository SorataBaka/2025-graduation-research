{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f04e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianharjuno/anaconda3/envs/sentiment/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"tianharjuno/twitter-parse\", cache_dir=\"cache/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1821b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "stage_1_source = dataset[\"source_stage_1\"]\n",
    "class_labels = ClassLabel(names=list(set(stage_1_source[\"relevant\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a19c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, unicodedata, jaconv\n",
    "\n",
    "_URL = re.compile(r\"https?://\\S+\")\n",
    "_MENTION = re.compile(r\"@\\w+\")\n",
    "_WS = re.compile(r\"\\s+\")\n",
    "_KUTI_CUT = re.compile(r\"(?i)kutipan.*$\", re.DOTALL)\n",
    "def cleantext(row: str):\n",
    "    text = row[\"content\"]  # type: ignore\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = jaconv.z2h(text, kana=False, digit=True, ascii=True)\n",
    "    text = text.replace(\"tanya grok\", \" \")\n",
    "    text = text.replace(\"grokproductivitypasang\", \" \")\n",
    "    text = text.replace(\"\\\\n\", \" \").replace(\"\\\\r\", \" \")\n",
    "    text = _URL.sub(\" <url> \", text)\n",
    "    text = text.replace(\"ini tidak tersedia\", \" \")\n",
    "    text = _MENTION.sub(\"@USER\", text)\n",
    "    text = re.sub(r\"^rt\\s+\", \"\", text, flags=re.I)\n",
    "    text = re.sub(r\"(\\b\\d{4})(?=[a-zA-Z])\", r\"\\1 \", text)\n",
    "    text = _KUTI_CUT.sub(\"\", text)\n",
    "    text = _WS.sub(\" \", text).strip()\n",
    "    row[\"content\"] = text  # type: ignore\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "488ea0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1_source = stage_1_source.map(cleantext, num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff77b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"tianharjuno/ruu-tni-relevancy-classification-p1\", cache_dir=\"cache/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tianharjuno/ruu-tni-relevancy-classification-p1\", cache_dir=\"cache/\")\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"content\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7945d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_source = stage_1_source.map(tokenize, batched=True, batch_size=128, num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c00ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "def compute_metrics(class_names):\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    def callback(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        if isinstance(logits, torch.Tensor):\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "        if isinstance(labels, torch.Tensor):\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "        macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "            labels, preds, average=\"macro\", zero_division=0\n",
    "        )\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        p_cls, r_cls, f1_cls, support_cls = precision_recall_fscore_support(\n",
    "            labels,\n",
    "            preds,\n",
    "            average=None,\n",
    "            zero_division=0,\n",
    "            labels=list(range(num_classes)),\n",
    "        )\n",
    "        metrics = {\n",
    "            \"accuracy\": acc,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"macro_precision\": macro_p,\n",
    "            \"macro_recall\": macro_r,\n",
    "        }\n",
    "        for idx, name in enumerate(class_names):\n",
    "            metrics[f\"{name}_precision\"] = p_cls[idx]  # type: ignore\n",
    "            metrics[f\"{name}_recall\"] = r_cls[idx]  # type: ignore\n",
    "            metrics[f\"{name}_f1\"] = f1_cls[idx]  # type: ignore\n",
    "            metrics[f\"{name}_support\"] = int(support_cls[idx])  # type: ignore\n",
    "        return metrics\n",
    "\n",
    "    return callback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    overwrite_output_dir=True,\n",
    "    eval_strategy=\"epoch\",  # evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",  # save checkpoint at the end of each epoch\n",
    "    learning_rate=1e-5,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.05,\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.01,\n",
    "    bf16=True,\n",
    ")\n",
    "compute_metrics_callback = compute_metrics(class_labels.names)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_source,\n",
    "    compute_metrics=compute_metrics_callback,\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae59e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianharjuno/anaconda3/envs/sentiment/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3db65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = predictions.predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae84d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_label_1 = (prediction_labels == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ac9b98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.int64(96199), np.int64(1): np.int64(105384)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Returns unique labels and their corresponding counts\n",
    "unique, counts = np.unique(prediction_labels, return_counts=True)\n",
    "\n",
    "# Combine them into a dictionary for easy reading\n",
    "label_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(label_counts)\n",
    "# Output example: {0: 120, 1: 450, 2: 30}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
