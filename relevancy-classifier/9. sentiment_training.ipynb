{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# clean the text",
   "id": "f9bb15b75542c2b2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T14:50:04.324344Z",
     "start_time": "2025-11-22T14:49:49.773187Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"tianharjuno/twitter-parse\", cache_dir=\"cache/\")\n",
    "train_ds = dataset[\"train_sentiment\"]\n",
    "test_ds = dataset[\"test_sentiment\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "563fed4457e3442d9420d06553adcc03"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "data/test_sentiment-00000-of-00001.parqu(â€¦):   0%|          | 0.00/1.46M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2501082bddf04e1a98a56ee52191f0e9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating source_stage_1 split:   0%|          | 0/201583 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "caab6086418d459eaded64c98681c79a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating source_stage_2 split:   0%|          | 0/247820 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bae60f0d03a4834863be06d82c7f01b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating cleaned split:   0%|          | 0/195952 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e86f1eb34ce44dd9b6a8ab45f3626e2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09304c6bf9ec4e2abb28b2d3909148dc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/19999 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3edb0a8afe04455997014175352beeb"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating source_labeled split:   0%|          | 0/247820 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1510dd7ddef046b2b93ba8dfe8cad399"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating train_sentiment split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd1ef1ff170740b5af10a5b228a42da6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating test_sentiment split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a11d4696b8a412aa507338c55bddab5"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:50:06.914017Z",
     "start_time": "2025-11-22T14:50:06.888679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re, unicodedata, jaconv, emoji\n",
    "\n",
    "_URL      = re.compile(r'https?://\\S+')\n",
    "_MENTION  = re.compile(r'@\\w+')\n",
    "_WS       = re.compile(r'\\s+')\n",
    "_KUTI_CUT = re.compile(r'(?i)kutipan.*$', re.DOTALL)\n",
    "\n",
    "# --- (MODIFIED) ---\n",
    "# Catches \"word\" + \"dari\" + \"domain.com\" -> replaces with \"word\"\n",
    "# Changed \\w+ to \\S+ to include punctuation like '!'\n",
    "_DARI_URL_ATTACHED = re.compile(r'(\\S+)dari\\s+([a-z0-9.-]+\\.[a-z]{2,})\\b', re.I)\n",
    "\n",
    "# Catches \" dari \" + \"domain.com\" -> replaces with empty string\n",
    "_DARI_URL_SPACED = re.compile(r'\\s+dari\\s+([a-z0-9.-]+\\.[a-z]{2,})\\b', re.I)\n",
    "\n",
    "# --- (NEW) ---\n",
    "# Catches any word ending in \"dari\" (e.g., \"anarko!dari\", \"negaradari\")\n",
    "_DARI_STUCK = re.compile(r'(\\S+)dari\\b', re.I)\n",
    "\n",
    "def cleantext(row: str):\n",
    "    text = row[\"content\"] #type: ignore\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    text = jaconv.z2h(text, kana=False, digit=True, ascii=True)\n",
    "    text = text.replace(\"tanya grok\", \" \")\n",
    "    text = text.replace(\"grokproductivitypasang\", \" \")\n",
    "    text = text.replace('\\\\n', ' ').replace('\\\\r', ' ')\n",
    "\n",
    "    # Handle standard URLs first\n",
    "    text = _URL.sub(' <url> ', text)\n",
    "    text = text.replace('ini tidak tersedia', ' ')\n",
    "\n",
    "    text = _MENTION.sub('@USER', text)\n",
    "    text = re.sub(r'^rt\\s+', '', text, flags=re.I)\n",
    "    text = re.sub(r'(\\b\\d{4})(?=[a-zA-Z])', r'\\1 ', text)\n",
    "    text = _KUTI_CUT.sub('', text)\n",
    "\n",
    "    # text = _DARI_URL_ATTACHED.sub(r'\\1', text)\n",
    "    # text = _DARI_URL_SPACED.sub('', text)\n",
    "    # text = _DARI_STUCK.sub(r'\\1', text)\n",
    "\n",
    "    text = _WS.sub(' ', text).strip()\n",
    "    row[\"content\"] = text #type: ignore\n",
    "    return row"
   ],
   "id": "11ef862a27369a64",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:50:12.186012Z",
     "start_time": "2025-11-22T14:50:10.845857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ds = train_ds.map(cleantext, num_proc=12)\n",
    "test_ds = test_ds.map(cleantext, num_proc=12)\n",
    "\n",
    "train_ds = train_ds.rename_column(\"sentiment\", \"label\")\n",
    "test_ds = test_ds.rename_column(\"sentiment\", \"label\")"
   ],
   "id": "9b11fded498f37d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2134bda4eca49d0b755298bc71caffd"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9e2da57ca5a4b3d80b7eb5db0623470"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# load the models and tokenize the data",
   "id": "b331132a08ae754a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:50:16.356290Z",
     "start_time": "2025-11-22T14:50:14.031886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import ClassLabel\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "class_labels = ClassLabel(names=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "model = AutoModelForSequenceClassification.from_pretrained('indolem/indobertweet-base-uncased', cache_dir=\"cache/\", num_labels=len(class_labels.names))\n",
    "tokenizer = AutoTokenizer.from_pretrained('indolem/indobertweet-base-uncased', cache_dir=\"cache/\")\n",
    "model.to(device)"
   ],
   "id": "104b5f318ddc0771",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobertweet-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31923, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:51:01.304976Z",
     "start_time": "2025-11-22T14:51:00.277322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"content\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "train_ds = train_ds.map(tokenize, batched=True, num_proc=12)\n",
    "test_ds = test_ds.map(tokenize, batched=True, num_proc=12)\n",
    "\n",
    "train_ds = train_ds.cast_column(\"label\", class_labels)\n",
    "test_ds = test_ds.cast_column(\"label\", class_labels)"
   ],
   "id": "1ef67018dd028d9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "417fdc7bfc75460f8beafaaa0a32436a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5514b2e01bd477685c3bf3442cae5a6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Casting the dataset:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b89c1a5943244cd8c297fa378051ae3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Casting the dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f3a7121265e4479ae446a0ce77b2f29"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:50:20.562018Z",
     "start_time": "2025-11-22T14:50:20.554057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(class_names):\n",
    "    num_classes = len(class_names)\n",
    "    def callback(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        if isinstance(logits, torch.Tensor):\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "        if isinstance(labels, torch.Tensor):\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "        macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "            labels, preds, average=\"macro\", zero_division=0\n",
    "        )\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        p_cls, r_cls, f1_cls, support_cls = precision_recall_fscore_support(\n",
    "            labels,\n",
    "            preds,\n",
    "            average=None,\n",
    "            zero_division=0,\n",
    "            labels=list(range(num_classes)),\n",
    "        )\n",
    "        metrics = {\n",
    "            \"accuracy\": acc,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"macro_precision\": macro_p,\n",
    "            \"macro_recall\": macro_r,\n",
    "        }\n",
    "        for idx, name in enumerate(class_names):\n",
    "            metrics[f\"{name}_precision\"] = p_cls[idx]  # type: ignore\n",
    "            metrics[f\"{name}_recall\"] = r_cls[idx]  # type: ignore\n",
    "            metrics[f\"{name}_f1\"] = f1_cls[idx]  # type: ignore\n",
    "            metrics[f\"{name}_support\"] = int(support_cls[idx])  # type: ignore\n",
    "        return metrics\n",
    "    return callback"
   ],
   "id": "8ee2bf7ff2dd67db",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:51:07.727663Z",
     "start_time": "2025-11-22T14:51:07.718976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class.\n",
    "            gamma (float, optional): Focusing parameter (default=2.0).\n",
    "            reduction (str, optional): Specifies the reduction to apply to the output.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # 1. Calculate standard Cross Entropy Loss without reduction (to get per-sample loss)\n",
    "        # Note: We do NOT apply weights here yet, because we need clean p_t for the focal term\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "\n",
    "        # 2. Get the probability of the true class (p_t)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "\n",
    "        # 3. Calculate the Focal term: (1 - p_t)^gamma\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "\n",
    "        # 4. Combine: loss = focal_term * ce_loss\n",
    "        loss = focal_term * ce_loss\n",
    "\n",
    "        # 5. Apply class weights (alpha) if provided\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[targets]\n",
    "            loss = loss * alpha_t\n",
    "\n",
    "        # 6. Apply reduction (mean or sum)\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "class FocalLossTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, gamma=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def compute_loss(self, input_model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = input_model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Move weights to the correct device (GPU/CPU)\n",
    "        if self.class_weights is not None:\n",
    "            weights = self.class_weights.to(logits.device)\n",
    "        else:\n",
    "            weights = None\n",
    "\n",
    "        # Initialize and compute Focal Loss\n",
    "        loss_fct = FocalLoss(alpha=weights, gamma=self.gamma)\n",
    "        loss = loss_fct(logits.view(-1, input_model.config.num_labels), labels.view(-1))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "id": "4b6774839ea671f8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:51:13.443311Z",
     "start_time": "2025-11-22T14:51:13.427386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Get counts\n",
    "true_labels = train_ds[\"label\"]\n",
    "label_counts = Counter(true_labels)\n",
    "n_classes = 3\n",
    "total_samples = sum(label_counts.values())\n",
    "\n",
    "# 2. Ensure weights are ordered by class index (0, 1, 2)\n",
    "# This is critical for CrossEntropyLoss\n",
    "class_indices = sorted(label_counts.keys()) # Assumes labels are 0, 1, 2\n",
    "counts = [label_counts[i] for i in range(n_classes)]\n",
    "\n",
    "# 3. Calculate Balanced Weights\n",
    "# Formula: Total / (Num_Classes * Count_Class)\n",
    "weights = [total_samples / (n_classes * c) for c in counts]\n",
    "\n",
    "my_weights = torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "print(f\"Class Counts: {counts}\")\n",
    "print(f\"Calculated Weights: {my_weights}\")"
   ],
   "id": "2f6da92ec9b6e3ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: [14500, 3820, 1680]\n",
      "Calculated Weights: tensor([0.4598, 1.7452, 3.9683])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:56:01.159779Z",
     "start_time": "2025-11-22T14:51:48.189240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers.training_args import TrainingArguments\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "training_args = TrainingArguments(\n",
    "    overwrite_output_dir=True,\n",
    "    eval_strategy=\"epoch\",     # evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",           # save checkpoint at the end of each epoch\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=256,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.05,\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.01,\n",
    "    fp16=True,\n",
    ")\n",
    "compute_callback = compute_metrics(class_labels.names)\n",
    "train_ds_split = train_ds.train_test_split(test_size=0.2, seed=42, stratify_by_column=\"label\")\n",
    "trainer = FocalLossTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_ds_split[\"train\"],\n",
    "    eval_dataset=train_ds_split[\"test\"],\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_callback,\n",
    "    class_weights=my_weights\n",
    ")\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ],
   "id": "ab139414c16da285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 04:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Negative Precision</th>\n",
       "      <th>Negative Recall</th>\n",
       "      <th>Negative F1</th>\n",
       "      <th>Negative Support</th>\n",
       "      <th>Neutral Precision</th>\n",
       "      <th>Neutral Recall</th>\n",
       "      <th>Neutral F1</th>\n",
       "      <th>Neutral Support</th>\n",
       "      <th>Positive Precision</th>\n",
       "      <th>Positive Recall</th>\n",
       "      <th>Positive F1</th>\n",
       "      <th>Positive Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.273500</td>\n",
       "      <td>0.192660</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>0.713470</td>\n",
       "      <td>0.680481</td>\n",
       "      <td>0.798037</td>\n",
       "      <td>0.961504</td>\n",
       "      <td>0.740690</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.479938</td>\n",
       "      <td>0.814136</td>\n",
       "      <td>0.603883</td>\n",
       "      <td>764</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.699752</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171100</td>\n",
       "      <td>0.172374</td>\n",
       "      <td>0.807250</td>\n",
       "      <td>0.757026</td>\n",
       "      <td>0.722440</td>\n",
       "      <td>0.821569</td>\n",
       "      <td>0.956737</td>\n",
       "      <td>0.800690</td>\n",
       "      <td>0.871785</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.542358</td>\n",
       "      <td>0.812827</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>764</td>\n",
       "      <td>0.668224</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.748691</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.138200</td>\n",
       "      <td>0.165579</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>0.769977</td>\n",
       "      <td>0.737196</td>\n",
       "      <td>0.830124</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>0.811724</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.560526</td>\n",
       "      <td>0.836387</td>\n",
       "      <td>0.671218</td>\n",
       "      <td>764</td>\n",
       "      <td>0.690244</td>\n",
       "      <td>0.842262</td>\n",
       "      <td>0.758713</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.169035</td>\n",
       "      <td>0.839750</td>\n",
       "      <td>0.783381</td>\n",
       "      <td>0.747637</td>\n",
       "      <td>0.836954</td>\n",
       "      <td>0.954246</td>\n",
       "      <td>0.848621</td>\n",
       "      <td>0.898339</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.612740</td>\n",
       "      <td>0.793194</td>\n",
       "      <td>0.691386</td>\n",
       "      <td>764</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.192012</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>0.784357</td>\n",
       "      <td>0.756352</td>\n",
       "      <td>0.839899</td>\n",
       "      <td>0.968124</td>\n",
       "      <td>0.816897</td>\n",
       "      <td>0.886104</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.565329</td>\n",
       "      <td>0.866492</td>\n",
       "      <td>0.684238</td>\n",
       "      <td>764</td>\n",
       "      <td>0.735602</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.782730</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.198228</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.797144</td>\n",
       "      <td>0.772081</td>\n",
       "      <td>0.840653</td>\n",
       "      <td>0.961871</td>\n",
       "      <td>0.843793</td>\n",
       "      <td>0.898971</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.596878</td>\n",
       "      <td>0.850785</td>\n",
       "      <td>0.701565</td>\n",
       "      <td>764</td>\n",
       "      <td>0.757493</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.790896</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.208628</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.798954</td>\n",
       "      <td>0.771053</td>\n",
       "      <td>0.841851</td>\n",
       "      <td>0.957817</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>0.902626</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.612560</td>\n",
       "      <td>0.829843</td>\n",
       "      <td>0.704836</td>\n",
       "      <td>764</td>\n",
       "      <td>0.742782</td>\n",
       "      <td>0.842262</td>\n",
       "      <td>0.789400</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.226386</td>\n",
       "      <td>0.842250</td>\n",
       "      <td>0.801372</td>\n",
       "      <td>0.780922</td>\n",
       "      <td>0.844315</td>\n",
       "      <td>0.966122</td>\n",
       "      <td>0.835862</td>\n",
       "      <td>0.896284</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.585814</td>\n",
       "      <td>0.875654</td>\n",
       "      <td>0.701994</td>\n",
       "      <td>764</td>\n",
       "      <td>0.790831</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.805839</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.226026</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.803649</td>\n",
       "      <td>0.780515</td>\n",
       "      <td>0.840773</td>\n",
       "      <td>0.957258</td>\n",
       "      <td>0.857241</td>\n",
       "      <td>0.904493</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.614203</td>\n",
       "      <td>0.837696</td>\n",
       "      <td>0.708749</td>\n",
       "      <td>764</td>\n",
       "      <td>0.770083</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.797704</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.229090</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.804875</td>\n",
       "      <td>0.781972</td>\n",
       "      <td>0.842701</td>\n",
       "      <td>0.958639</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.845550</td>\n",
       "      <td>0.710671</td>\n",
       "      <td>764</td>\n",
       "      <td>0.774373</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "33f48d7b56637510a1d415ab212a1d3d"
     }
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=0.11406148338317872, metrics={'train_runtime': 252.8152, 'train_samples_per_second': 632.873, 'train_steps_per_second': 4.944, 'total_flos': 1.052453670912e+16, 'train_loss': 0.11406148338317872, 'epoch': 10.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:56:13.981505Z",
     "start_time": "2025-11-22T14:56:09.169045Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(test_ds)",
   "id": "7b92840adf0e7ad3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "e9efde8b15ab7833abcd33b365d823bb"
     }
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.21958070993423462,\n",
       " 'eval_accuracy': 0.8436,\n",
       " 'eval_macro_f1': 0.8018332281076606,\n",
       " 'eval_macro_precision': 0.7843743480557018,\n",
       " 'eval_macro_recall': 0.8280194155243551,\n",
       " 'eval_Negative_precision': 0.9400246685168054,\n",
       " 'eval_Negative_recall': 0.8574040219378428,\n",
       " 'eval_Negative_f1': 0.896815474001618,\n",
       " 'eval_Negative_support': 7111,\n",
       " 'eval_Neutral_precision': 0.6296433878157504,\n",
       " 'eval_Neutral_recall': 0.8052256532066508,\n",
       " 'eval_Neutral_f1': 0.7066916823014384,\n",
       " 'eval_Neutral_support': 2105,\n",
       " 'eval_Positive_precision': 0.7834549878345499,\n",
       " 'eval_Positive_recall': 0.8214285714285714,\n",
       " 'eval_Positive_f1': 0.8019925280199253,\n",
       " 'eval_Positive_support': 784,\n",
       " 'eval_runtime': 4.8029,\n",
       " 'eval_samples_per_second': 2082.058,\n",
       " 'eval_steps_per_second': 8.328,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:58:07.431228Z",
     "start_time": "2025-11-22T14:57:44.748389Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.model.push_to_hub(\"tianharjuno/ruu-tni-sentiment-classification\", commit_message=\"Initial Commit\")",
   "id": "4d57527c2a7246b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6adf65abafe45aaa36560329fb37e94"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "935825c362ac4a17be10f0bc15cb360f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  /tmp/tmpkzhsgd63/model.safetensors    :   0%|          |  557kB /  442MB            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "126dfb63ec9d42a9b57df3804f3c205b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/tianharjuno/ruu-tni-sentiment-classification/commit/104bbd3485e036bd1d891174910cdd472f9b4497', commit_message='Initial Commit', commit_description='', oid='104bbd3485e036bd1d891174910cdd472f9b4497', pr_url=None, repo_url=RepoUrl('https://huggingface.co/tianharjuno/ruu-tni-sentiment-classification', endpoint='https://huggingface.co', repo_type='model', repo_id='tianharjuno/ruu-tni-sentiment-classification'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:58:09.610047Z",
     "start_time": "2025-11-22T14:58:07.608885Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.push_to_hub(\"tianharjuno/ruu-tni-sentiment-classification\", commit_message=\"Initial Commit\")",
   "id": "785423580b27570f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/tianharjuno/ruu-tni-sentiment-classification/commit/104bbd3485e036bd1d891174910cdd472f9b4497', commit_message='Initial Commit', commit_description='', oid='104bbd3485e036bd1d891174910cdd472f9b4497', pr_url=None, repo_url=RepoUrl('https://huggingface.co/tianharjuno/ruu-tni-sentiment-classification', endpoint='https://huggingface.co', repo_type='model', repo_id='tianharjuno/ruu-tni-sentiment-classification'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:03:22.026378Z",
     "start_time": "2025-11-22T15:03:13.196171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "whole_label_ds = dataset[\"source_labeled\"]\n",
    "related_ds = whole_label_ds.filter(lambda x: x[\"relevant\"] == True)\n",
    "related_ds = related_ds.map(cleantext, num_proc=20)\n",
    "related_ds = related_ds.map(tokenize, num_proc=20, batched=True, batch_size=128)"
   ],
   "id": "9e86ecdada92e271",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/147701 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a0db87f2a554939ac47a550a7ab40a6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:04:30.834488Z",
     "start_time": "2025-11-22T15:03:22.485128Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = trainer.predict(related_ds)",
   "id": "c58764e1e17a6314",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:05:32.862598Z",
     "start_time": "2025-11-22T15:05:32.855590Z"
    }
   },
   "cell_type": "code",
   "source": "predicted_labels = predictions.predictions.argmax(axis=1)",
   "id": "c63bee81d4b32430",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:07:45.086434Z",
     "start_time": "2025-11-22T15:07:35.148091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Create a lookup dictionary: { tweet_id_string : predicted_label_int }\n",
    "# We cast IDs to string to prevent the Int64 vs String mismatch errors you saw earlier.\n",
    "# Accessing column by name related_ds['tweet_id'] is faster than iterating rows.\n",
    "relevant_ids = [str(x) for x in related_ds['tweet_id']]\n",
    "prediction_map = dict(zip(relevant_ids, predicted_labels))\n",
    "\n",
    "print(f\"Mapped {len(prediction_map)} predictions.\")\n",
    "\n",
    "# 2. Define the merging function\n",
    "def apply_predictions(example):\n",
    "    t_id = str(example['tweet_id'])\n",
    "\n",
    "    # If the tweet was in our relevant batch, assign the prediction.\n",
    "    # If not (or if relevant=False), assign -1.\n",
    "    example['sentiment'] = int(prediction_map.get(t_id, -1))\n",
    "\n",
    "    return example\n",
    "\n",
    "# 3. Apply to the WHOLE dataset\n",
    "# This effectively \"resets\" everyone to -1, then selectively updates the relevant ones.\n",
    "final_ds = whole_label_ds.map(apply_predictions)\n",
    "\n",
    "# Verification\n",
    "print(\"Label counts in final dataset:\")\n",
    "from collections import Counter\n",
    "print(Counter(final_ds['sentiment']))"
   ],
   "id": "9396b48ff27f0e38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped 147701 predictions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/247820 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f776dc128a984040a73309e9b2f6d8d9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts in final dataset:\n",
      "Counter({0: 104955, -1: 100119, 1: 31335, 2: 11411})\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:09:39.302909Z",
     "start_time": "2025-11-22T15:09:18.281284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset[\"source_labeled\"] = final_ds\n",
    "dataset.push_to_hub(\"tianharjuno/twitter-parse\", commit_message=\"Labeled sentiment\")"
   ],
   "id": "9bde9efc803b3a54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23975dbd13544a71b5e52c7e211f97c2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/202 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f14f376b1dff47c5a338c61dfbdd95a9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63763a0802d3408b907ca14773de1952"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/248 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a55b597e3e942769254615cdc9d407c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2637a579eb9045bb8a300f1cb9cd5b46"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/196 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d853211e78e74097b8028380f581ec1e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aad939ffb48f41188f401e65d0d2c69b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5fd325ccaa954c82836dfafdf17266bc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afd8360fd0f04ba18b330fdf77aed01f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a49f2c2b7bf4c47b9531d2b1350cc9a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56a8229d3aa34c5a845a24fcecf20304"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/248 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e5fdfbdfdbd4dbe97ccac60ee44b1ab"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f523dbfa184947f68d67c671ef1e1102"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc69bb4904a24bffbbdde97af58983cb"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fbf14fb0b8b4e17b1a034fcc762e769"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "174a8bee7cbb4d059ee0f1d4dbc428bd"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/tianharjuno/twitter-parse/commit/10a15a58ddb21f02087ecd00dfda85978e3fcc46', commit_message='Labeled sentiment', commit_description='', oid='10a15a58ddb21f02087ecd00dfda85978e3fcc46', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/tianharjuno/twitter-parse', endpoint='https://huggingface.co', repo_type='dataset', repo_id='tianharjuno/twitter-parse'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
